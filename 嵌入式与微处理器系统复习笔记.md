# 嵌入式与微处理器系统复习笔记


# 微处理器基本概念（≤10%）

---

## 微处理器基本结构 ALU CPU MMU

- 处理器字长：处理器ALU和通用数据寄存器位宽
- ALU、CPU 略
- MMU：
    - 控制虚拟地址（VA）映射到物理地址（PA）
    - 控制内存的访问权限
    - 控制可缓存性和缓冲性

## 通常的评估处理器性能的基本参数，指标，如MIPS，CPI

- CPI = 一个程序运行的CPU时钟周期/该程序的指令数
- MIPS = 每秒百万条指令 = 指令数/（指令的运行时间×10^6） = 时钟频率/（CPI×10^6）
- MFLOPS = 每秒百万次浮点运算次数/（浮点运算的时间×10^6）

## 处理器指令执行过程，取指，译码，执行，写回

## 流水线，影响流水线的因素

- 结构冲突，多条指令同时争用同一资源导致的冲突
- 数据冲突
- 控制冲突

## cache的命中率，影响cache命中率的因素

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled.png)

> 概念
> 

Cache命中率是衡量Cache性能的一个指标。 它表示的是系统在访问数据时，成功从Cache中获取数据的比例。（Cache命中次数÷存储器请求次数）×100％

> 因素
> 
- 容量：Cache的命中率随它的容量的增加而提高，它们之间的关系曲线如图所示。在Cache容量比较小的时候，命中率提高得非常快，但根据边际效应递减原理随着Cache容量的增加，命中率提高的速度逐渐降低。
    
    ![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%201.png)
    
- 块大小：对于给定的Cache容量，当块大小增加时，命中率开始时处于上升趋势，后来反而会下降。
    
    ![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%202.png)
    
- 与主存的映射方式：
1. 全相联方式
应用全相联方式命中率比较高，Cache存储空间利用率高。但是访问相关存储器时，每次都要与全部内容比较，速度低，成本高，因而应用少。
2.  直接相联方式
应用直接相联方式地址映像方式简单，数据访问时，只需检查区号是否相等即可，因而可以得到比较快的访问速度，硬件设备简单。但是使得替换操作频繁，命中率比较低。
3. 组相联映像方式
应用组相联方式块的冲突概率比较低，块的利用率大幅度提高，块失效率明显降低。但是实现难度和造价要比直接映像方式高。
- 替换策略

近期最少使用（LRU）> 先进先出（FIFO) > 随机（RAND）

## 程序开发过程，编译，汇编，链接的输入输出

嵌入式开发流程比PC开发流程多一个下载，编辑、编译、汇编、链接、（下载）、调试

## 异常与中断

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%203.png)

# ARM(60%)

---

## ARM处理器

### ARM9内核

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%204.png)

💡R13 sp， R14 lr,  R15 pc

**❗移位特性，访存特性（load store架构，访存专用指令）RISC架构**

RISC，即精简指令集计算机，是一种处理器架构，其特点是指令集精简、简单明了。RISC架构的处理器通常只支持有限的指令集，且这些指令的执行速度非常快。这种设计使得RISC架构的处理器在功耗、性能等方面具有优势。常见的RISC架构处理器包括ARM和MIPS等。

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%205.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%206.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%207.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%208.png)

### 异常模式

- 异常向量、异常模式

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%209.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2010.png)

位于CPSR最低字节，C位（控制域），CPSR的高8位为标志域，存放nzcvqift

### LoadStore 架构

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2011.png)

## ARM指令

### 格式

- 指令格式

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2012.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2013.png)

### 变量与常量

**寄存器常量装载方式**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2014.png)

```nasm
**Imagewidth    equ    160
Imageheight   equ    120**
```

```nasm
;初始化 r5=0，r6=0
  mov r5, #0
  mov r6, #0
;初始化 r5=0，r6=0
  ldr r5 , =0
  ldr r6,  =0

```

**MOV指令**

必须是8-bit，0x0 - 0xff （0-255），并可以通过任意偶数移位

❓指出下列错误的指令

```nasm
MOV r0, #0x55 ;R0 = 0x55
MVN r0, #0x55 ;R0 = 0xffffffaa

MOV rn ,#1025 错
MOV rn ,#4096 对
MVN rn ,#0x111 错
MVN rn ,#0xffffffff 对
```

```nasm
；PRE
  ；R0=0x80
  ；R1=0x50
MOV R0, R1, LSL #4
；POST 
  ; R0 = 0x500
  ; R1 = 0x50
```

**LDR指令**

如果是在上述范围内，就等同于执行MOV (MVN)

否则

- Places the value in a literal pool
- LDR -> program-relative address, reads the constant from the literal pool.
- 地址要存放在±4KB范围内，如果是thumb指令，则是±1KB

等同于LDR      rn, [pc, #offset to literal pool]

❓为什么 “LTORG” 要放在跳转后或返回后？

不会当作指令取进去 

**ADR指令**
伪指令，需要能够转换成一条指令（ADD，SUB） 可以获取±1MB的地址

```nasm
start
    ……
    ……
    ADR r0, start
    ADR r1, next
    ……
    ……
next
    ……	 

```

```nasm
start
    ……
    ……
    SUB r0, pc, #offset1
    ADD r1, pc, #offset2
    ……
    ……
next
   ……	
```

**ADRL指令**

伪指令，需要能够转换成两条指令（ADD，SUB）

```nasm
start
    ……
    ……
   ADRL r0, start
   ADRL r1, next\
          +0x2000
    ……
    ……
next
    ……	 

```

```nasm
start
    ……
    ……
    SUB r0, pc, #offset1
    SUB r0, r0, #offset1_1
    ADD r1, pc, #offset2
    ADD r1, r1, #offset2_2
    ……
    ……
next
   ……	 

```

## 运算指令，ADD(S)，SUB(S)，注意label

### Overview

> 语法
> 

**Op{cond}{s} Rd, Rn, shift_operand**

> 标志位
> 

**N, Z, C,V**

### 加法/减法

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2015.png)

> 移位
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2016.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2017.png)

ASR：算术右移， LSR：逻辑右移，ROR：循环右移，LSL：逻辑左移，RRX：带扩展的循环右移

- <shifter_imm>：L：0-31，R：1-32
- RRX只能移动一位

❓指出下列错误的指令

```nasm
ADC	r1, r1, #5 ;对
SUB 	r11, r12, r3, ASR #5 ;对 
RSB 	r5, r3, r4, LSR #32 ;对
ADD 	r3, r7, #1023 ;错, in range 0-255               
SUB 	r11, r12, r3, LSL #32 ;错
SBC 	r5, r4, r4, RRX #3 ;错
```

❓下列两条指令的运行结果

```nasm
;PRE
  ;R0=0x00
  ;R1=0x02
  ;R2=0x01
  ;cpsr=nzcvqiFt_USER
	
  SUBS  R0, R1, R2

;POST
  ;R0=?
  ;R1=?
  ;cpsr=?

```

```nasm
;PRE
     ;R0=0x00
     ; R1=0x000000C
     ; R2=0x01

      RSB  R0, R1, R2 LSL #2

;POST
       ;R0=0xfffffff8
       ;R1=0x0000000C

```

### 乘法

> MUL/MLA
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2018.png)

❗**d≠m 32bits*32bits = low 32bits**

> UMULL/UMLAL
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2019.png)

❓下列指令的运行结果

```nasm
PRE
R0=0x00	
R1=0x02
R2=0x02

MUL  R0, R1, R2

POST
R0=4
R1=R1
R2=R2
```

```nasm
PRE
R0=0x00
R1=0x00
R2=0xf0000002
R3=0x02

UMULL  R0, R1, R2, R3

POST
R0=0xe0000004
R1=0x1
	
```

### 逻辑

**Op{cond}{s}  Rd, Rn, shift_operand**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2020.png)

### 比较

**Op{cond}  Rn, shift_operand**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2021.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2022.png)

## 跳转指令的各种变种（B, BL, BX, BLX）

### Overview

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2023.png)

**❓B 跳转最大地址距离：±32MB**

lr存放了跳转前下一条指令的地址

条件跳转 & 非条件跳转（有时间再看看） 

BMI：N set

E和T结尾的基本都是signed，LS和HI则是unsigned

### 条件执行

```nasm
ADD     r0, r1, r2    
ADDS    r0, r1, r2    
ADDCSS  r0, r1, r2    ; If C flag set then r0 = r1 + r2, 	and update flags
```

❓以下程序中那些指令不执行

```nasm
  MOV r0, #1
	MOV r1, #2
	CMP r0, r1
	SUBGT r0,r0,r1 ;不执行
	SUBLT r1,r1,r0 ;执行，r1=1
		CMP r0,r1
	SUBGT r0,r0,r1 ;不执行
	SUBLT r1,r1,r0 ;不执行

```

## load/store 各种变种

### 内存分配

**定义**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2024.png)

**举例**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2025.png)

加U不需要对齐

```c
//Declare 
typedef struct Point
{
    	float x;
  	float y;
	float z;
} Point;

//Allocate space
Point origin;

```

```nasm
//Declare 
PointBase   RN      r11
                    MAP     0, PointBase
Point_x       FIELD   4
Point_y       FIELD   4
Point_z       FIELD   4

//Allocate space
origin  	SPACE   12
; MAP定义起始地址
; FIELD定义长度
; SPACE分配内存空间
```

### 读内存指令

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2026.png)

进行有符号的LD的时候，不支持移位特性，且offset由12位缩减为8位

**Address1**

- [Rn]
- **前偏移，Rn不变**
    - [Rn, # +/- offset_12]
    - [Rn, +/-Rm]
    - [Rn,+/-Rm, shift_imm]
- **前偏移，Rn更新**
    - [Rn,#+/-offset_12]!
    - [Rn,+/-Rm]!
    - [Rn,+/-Rm, shift_imm]!
- **后偏移，Rn更新**
    - [Rn], # +/- offset_12
    - [Rn], +/-Rm
    - [Rn],+/-Rm, shift_imm

```nasm
ldr 	r0, [r1, #0x04]!
ldr 	r0, [r1, r2]! ;r1+r2->r0， 更新r1
ldrh 	r2,[r1, -r0, LSR #0x04]! ;r1-r0 << 0x04 -> r2 更新r1
ldrb 	r0, [r1], #0x04 ; r1 -> r0 r1+4->r1
ldr 	r0,[r1],r2
rdr 	r0,[r1], -r0, LSL #0x04   
ldrsb r0, [r1, #0x04]
ldrh 	r0, [r1, r2]
ldr 	r2,[r1, -r0, LSR #0x04]
```

**❓下列指令的执行结果**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2027.png)

```nasm
LDR r0, [r1, #4]  ; r0 = 0x30303030, r1 = 0x104
LDR r0, [r1, #4]! ; r0 = 0x30303030, r1 = 0x108
LDR r0, [r1], #4  ; r0 = 0x80808080, r1 = 0x108
LDRB r0, [r1]     ; r0 = 0x80      , r1 = 0x104
LDRSB r0, [r1]    ; r0 = 0xffffff80, r1 = 0x104
```

**❓下列指令，哪些是正确的**

```nasm
LDR r1, r2, r3 ;错
LDR r1, [r2, #0x111] ; 对
LDR r1, [r2], +#0x11111 ; 错
LDRSB r1, [r2], -#0x111 ; 错
LDRH  [r1], r2  ; 对
LDRSH r1, [r2, r3] ; 对
LDRB r1, [r2,-r3] ; 对

```

### 写内存指令

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2028.png)

**双字访问**

```nasm
    LDRD    r6,[r11]
    STRD    r4,[r9,#24]
    STRD    r0,abcd
    LDRD    r1,[r6]        ; Rd 必须为偶数
    STRD    r14,[r9,#36]   ; Rd 不能是R14.
    STRD    r2,[r3],r6     ; Rn 不能是 Rd 或 R(d+1).
```

**交换数据**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2029.png)

❓分析下面指令的执行结果

```nasm
mem32[0x8000]=0x12345678
R0=0x00000000
R1=0x22223333
R2=0x8000

SWP r0, r1, [r2]

mem32[0x8000]=0x22223333
R0=0x12345678
R1=0x22223333
R2=0x8000

```

### 多数据访问

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2030.png)

❗**内存中的地址顺序与寄存器序号对应，与列表中的次序无关！** 
❓**分析下列指令的结果**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2031.png)

```nasm
LDMIA r0!,{r1-r3} ; r1 = 0x005, r2 = 0x006, r3 = 0x007, r0 = 0x8002c
LDMDA r0, {r3,r2}
LDMIB r0!,{r1-r3} ; r1 = 0x006, r2 = 0x007, r0 = 0x8002c
LDMDB r0, {r3,r2}
STMIA r0!,{r1-r3}
STMDA r0, {r3,r2}
STMIB r0!,{r1-r3}
STMDB r0, {r3,r2}
```

**栈操作**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2032.png)

- 向上生长，pop时地址后减 pop：LDMFA = LDMDA，push：STMFA = STMIB
- 向上生长，pop时地址先减 pop：LDMEA = LDMDB，push：STMEA = STMIA
- 向下生长，pop时地址后增 pop：LDMFD = LDMIA，push：STMED = STMDB
- 向下生长，pop时地址先增 pop：LDMED = LDMIB， push：STMED = STMDA

### **预计算**

**❓“ subs   r10, r10, #8*4”中，“ 8*4”** **在指令执行时计算？**

💡在汇编器中计算，而非在处理器中计算

**保留字**

**r0-r15 and R0-R15，a1-a4 (r0 to r3)，v1-v8 (r4 to r11)，sb and SB(r9)，sl and SL (r10)，fp and FP (r11)，ip and IP (r12)，sp and SP (r13)，lr and LR (r14)，pc and PC (r15).**

**预计算**

双目计算、字符串、单目计算

```nasm
LDR r0, =? mydata ; 4*10
LDR r1, =? Mydata1 ; 1*4
				
mydata     DCD 1,2,3,4,5,6,7,8,9,0
Mydata1    DCB ‘a’, ‘b’, ‘c’, ‘d’
```

```nasm
datastruc     	SPACE   280    
            	  MAP    	0,r8 ; 
consta          FIELD   4
constb         	FIELD   4
x               FIELD   8
y          		  FIELD   8
string          FIELD   256
           ……
LDR r3,=:BASE:y  ; 获取基地址
LDR r4,=:INDEX:y ; 获取偏移

```

### **宏定义**

```nasm
		MACRO                                  
$LOOP		MacSum $RD                             
		MOV v8, #0             
      
$LOOP.1 	ADD v8, $RD, v8
    SUBS $RD, $RD, #1
    BNE $LOOP.1
    MOV $RD, v8      
    MEND 
AREA mycode, CODE  
		ENTRY   
		CODE32                             
START   
     MOV R0, #100            
add100		MacSum R0                           
STOP
		b  STOP
    END

```

1. **$LOOP 是参数吗？**

是宏标签

1. **如果宏定义中去掉$LOOP, 用确定lable“loop”替代“$LOOP.1”, 程序运行的结果会有变化吗？**

多次引用，标签重复

1. **$LOOP.1的作用？**

局部标签，宏定义体内有效

### 64位计算

**64位整数加减法**

```nasm
LDR	R0, =0x00000022  ;加载第一个数的高32位放到R0中
LDR	R1, =0x00330044   ;加载第一个数的低32位放到R1中
LDR	R2, =0x00000098			
LDR	R3, =0x76543210			
LDR	R6, =0x20000000   ;把存储结果的内存地址放到R6中
ADDS	R4, R1, R3（ SUBS  R4, R1, R3 ）	;低32位加（减），R4存储低32位
ADC	R5, R0, R2 （ SUBC  R5, R0, R2 ） ;高32位加（减），R5存储高32位
STMIA	R6!,{R4,R5}   ;将R4，R5的数据存储到R6指向的地址上，R6值更新
```

**64位无符号数相乘，得到64位无符号数**

```nasm
Mul_64 to 64
stmfd	sp!, {r4,r5,lr}
umull	c_0,c_1, a_0, b_0 	;low *low 
mla	c_1, a_0,b_1,c_1	;low *high
mla 	c_1, a_1, b_0, c_1	;high* low
  
mov 	r0, c_0
mov	r1, c_1			;return

```

**64位有符号数相乘，得到128位结果**

## Debug

在Keil工具里build info （根据RO，RW，RI评估系统用的RAM和ROM资源），出现error的时候应该怎么解决（如link error，未定义变量），c是编译错误（c代码错误），a是汇编错误（汇编格式错误），l链接错误（库不全，地址分配资源不够）

**Total RO  Size (Code + RO Data)**

**Total RW  Size (RW Data + ZI Data)         RW-data代表已初始化的数据，ZI-data代表未初始化的数据**  

**Total ROM Size (Code + RO Data + RW Data)**

## ATCPS

ATCPS，参数传递，调用返回，中断

**参数传递和调用返回**

```nasm
寄存器约定
R0-r3 (a1-a4) 传递参数
R4-r11 (v1-v8)保存局部变量 （r4-r7 for Thumb)
R12 (ip) 过程间自定义数据交换
R13 (sp) 数据堆栈指针
R14 (lr) 保存子程序的返回地址
R15（pc）

参数传输规则
〈 =4， r0-r3,依次
大于4，存入数据栈，最后一个数据先入栈

浮点参数传递(顺序传递)
FPA (Floating Point Arithmetic)
     f0-f7 (s0-s7, d0-d7,e0-e7)
VFP (d0-d15, s0-s31)

参数返回规则（续）
结果为32bit整数时，通过r0传递
结果为64bit整数时，通过r0和R1传递
结果为浮点数时，通过浮点寄存器返回(f0,d0)
更多的数据通过内存返回

```

**嵌入式汇编**

- **不支持 LDR Rn,= XXX 和 ADR, ADRL 伪指令**
- **不支持 BX**
- **用”&”替代 “0x”** **表示16位数据**

### 异常处理

**向量表**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2033.png)

**直接赋值实现**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2034.png)

**跳转实现**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2035.png)

**注册异常处理程序**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2036.png)

**中断向量扩展**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2037.png)

**中断嵌套**

非嵌套：禁止中断→保存上下文→中断处理→中断服务→恢复上下文→允许中断→返回

嵌套    ：禁止中断→保存上下文→切换到SVC模式→保存到SVC堆栈→允许中断→中断服务→恢复上下文→返回

ldmfd  sp!, {r0-r3, r12, r14}^中^的意义是在系统模式下,同时加载用户模式下的寄存器值。

**SWI**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2038.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2039.png)

swi的声明： __swi(0) int add_four(int, int, int, int);      

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2040.png)

过程：声明一个swi函数，指定软中断号，然后注册异常处理程序，接着跳转到SWI_Handler获取中断号参数和其他运算参数，进入C_SWI_Handler。具体跳转过程参考我的作业。

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2041.png)

保存现场和push栈帧的区别：保存现场是保存R0-R12, R14; push栈帧是保存R4-R8, R14

**Scatter Scripts（没说要考，感兴趣）**

- 文本文件 .sct
- Linker 脚本文件；
- 控制二进制程序和数据组件的分组和地址分配；
- 映射中的每个区域都可以具有不同的加载和执行地址；

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2042.png)

> .icf文件
> 

为链接器提供有关可能地址的最大大小的信息，并定义可用的物理内存，以及处理可以以不同方式寻址的内存。 例如定义内存位置、内存大小和堆栈大小

**启动程序分析 (S3C2410A)**

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2043.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2044.png)

> Reset
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2045.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2046.png)

通过IRQ_Entry中的中断扩展向量跳转进入Reset_Handler

> Reset_Handler
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2047.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2048.png)

# 程序优化（≤5%）

---

### Overview

**目标**

> **程序优化** 在不改变程序功能的情况下，使程序运行速度更快，占用空间更小，能耗更低
> 

> **优化原则**
> 
- 等效原则，功能一致
- 有效原则，运行速度、占用空间、能耗低，或三者兼有
- 经济原则，较小代价

**手段**

- 算法优化，选择一种高效的算法
- 数据结构优化，采用访问速度更快的数据结构
- 编译优化，配置合适的编译选项
- 代码优化，用汇编语言或精简的程序代码代替原有的代码

### 速度优化

**目标**

- 减少指令数
- 减少运行时间：1、周期； 2、数据访问

**手段**

- **访存对齐：**如果某类型数的存访地址是自然边界的整数倍（对齐），则访问效率最高   ****
- **数据类型：**少用char，少用short，多用int，非负数用无符号整数，浮点转定点
- **循环体：**
    - 循环展开：减少循环迭代次数，减少跳转指令
    - 固定次数循环：for循环用递减较优，不定次数循环，do while优于for循环
- **计算替换：**
    - 减少重复运算
    - 利用加法替换乘法和索引
    - 改变指令顺序，减少指令间的依赖
    - 查找表
- **访存管理：**
    - 访问连续的数据区，充分利用cache
    - 使用TCM，将计算量较大的代码和常用数据放到片内RAM中
    - 减少访存次数
- **分支跳转：**
    - 对于case语句，把可能发生的case放在前面

### 资源优化

**手段**

- **减小程序空间**
    - 选择短长度指令集
    - 计算替换
    - 循环替换  (do while 由于 for )
    - 数据类型（unsigned int 优于 int)
    - 取消内联函数
- **结构体、空间复用**

### 功耗优化

**手段**

- 程序执行功耗
    - 减少指令数
    - 选用功耗低的指令
- 系统管理
    - 降低主频
    - 状态管理
    - 模式管理
- 控制系统
    - 减少访存次数
    - 关断空闲外设

# RISC-V（5%-10%）

---

## RISC-V的结构特点，重点比较RISC-V和ARM的区别，开源处理器的开源内容是什么

### 特点

简洁性、架构和实现的分离、易于编程、编译、链接、程序大小降低

- **模块化**
    - 支持模块化可配置的指令子集
- **可扩展性**
    - 支持可扩展定制指令
- **易实现性**
    - 硬件设计与编译器实现非常简单
        - 仅支持小端模式
        - 规整的指令编码格式
        - 不使用指令条件编码
        - 存储器访问指令一次只访问一个元素
        - 去除存储器访问指令的地址自增和自减模式

### 与ARM的区别

指令编码更规整

没有地址自增/自减的访存指令

没有条件执行

没有改变标志位

…

**开源处理器的开源内容**

1. 处理器架构的规范和设计文档: 这包括指令集架构、寄存器定义、内存管理等基本结构的详细说明。
2. 处理器 RTL （寄存器传输级）源代码: 这是用硬件描述语言（如 Verilog 或 VHDL）编写的处理器核心实现代码。
3. 模拟和验证测试用例: 用于验证处理器行为正确性的各种测试程序和输入数据集。
4. 编译器和工具链: 通常会提供处理器的编译器前端、汇编器、链接器等支持工具。
5. 参考操作系统和应用程序: 一些开源处理器会提供参考设计的操作系统以及基础应用程序。
6. 文档和教程: 涵盖处理器使用、编程、性能优化等方方面面的指南和说明。

# 多核处理器（≥20%）

---

## OpenMP

```c
#include "stdafx.h"
#include "omp.h"
int _tmain(int argc, _TCHAR* argv[]){     
     printf("Hello from serial.\n");
     printf("Thread number = %d\n",
     omp_get_thread_num());  //serial
    #pragma omp parallel {       //parallel
     printf("Hello from parallel.Thread number 
          = %d\n",omp_get_thread_num());
     }
     printf("Hello from serial again.\n");
     return;
}

```

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2049.png)

### 循环并行化，如果有多层循环在哪一层并行效果较好

循环并行概念：

**#pragma omp parallel for [clause[clause…]]**

```c
int step = 20;
int _tmain(int argc, _TCHAR* argv[]){
    int i;
   #pragma omp parallel for
   for (i = 0; i< step; i++){
       printf("i = %d\n", i);}
   return 0;
}

```

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2050.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2051.png)

以下两段程序是等效的

```c
#pragma omp parallel {	
    #pragma omp for
    for (i=0;i< MAX; i++){
    res[i] = huge();
    } 
}	

```

```c
#pragma omp parallel for
for (i=0;i< MAX; i++){    
  res[i] = huge();
} 
```

右边形式作用域只是紧跟着的那个for循环，而左边形式在整个并行块中可以出现多个for制导指令。

这也就意味着，假如想在两个做了循环并行的for循环中间插入一条单线程语句，右边就不用管，左边则需要加上#pragma omp master 或 #pragma omp single，如下所示

```c
#pragma omp parallel
	{
#pragma omp for
		for (int i = 0; i < 6; i++)
			printf("i = %d, I am Thread %d\n", i, omp_get_thread_num());
#pragma omp master
		{
			//这里的代码由主线程执行
			printf("I am Thread %d\n", omp_get_thread_num());
		}
#pragma omp for
		for (int i = 0; i < 6; i++)
			printf("i = %d, I am Thread %d\n", i, omp_get_thread_num());
	}

```

```c
#pragma omp parallel for
	for (int i = 0; i < 6; i++)
		printf("i = %d, I am Thread %d\n", i, omp_get_thread_num());
	//这里是两个for循环之间的代码，将会由线程0即主线程执行
	printf("I am Thread %d\n", omp_get_thread_num());
#pragma omp parallel for
	for (int i = 0; i < 6; i++)
		printf("i = %d, I am Thread %d\n", i, omp_get_thread_num());
```

### 变量私化

```c
ifirst = 10;
int k[600];
int i, j,i2;
for(j = 0; j <= 60; j++){
	for(i=0;i<6000000;i++){ 
     i2 = i-(i/600)*600;
     k[i2] = ifirst + i;}
}
// time = 1505

ifirst = 10;
int k[600];
int i,j,i2;
for(j = 0; j <= 60; j++){
#pragma omp parallel for
	for(i=0;i<6000000;i++){ 
     i2 = i-(i/600)*600;
     k[i2] = ifirst + i;}
}

// time = 2140
```

加了pragma parrelle for反而变慢的原因是：所有线程会访问同一个共享变量，需要将这个变量私有化，循环的索引本身就是线程私有的

```c
ifirst = 10;
int k[600];
int i,j,i2;
for(j = 0; j <= 60; j++){
#pragma omp parallel for private(i2)
	for(i=0;i<6000000;i++){ 
     i2 = i-(i/600)*600;
     k[i2] = ifirst + i;}
}
// time = 910
```

注意，它是在for循环前面

### 变量保护

```c
float RES;
float B; 
#pragma omp parallel forfor(int i=0; i<niters; i++){
  B = big_job(i);
#pragma omp critical (RES_lock)  consum (B, RES);}}
```

```c
unsigend sum = 0.0;
float a[LP_N],b[LP_N];
sum=0.0;
#pragma omp parallel for
for(int i=0; i<LP_N; i++) {
  #pragma omp critical (sum_lock)	
   sum += abs(10*sin(double(a[i] *    
     (b[i]+1)/ (b[i] + a[i] + 1))));}
printf("sum=%d\n", sum);  
```

这样能保证正确的结果，但时间较长，因为临界区是这样的，注意这里pragma omp critical在循环内

```c
unsigend sum = 0.0;
float a[LP_N],b[LP_N]; 
sum=0.0;
#pragma omp parallel for reduction(+:sum)
for(int i=0; i<LP_N; i++) {
	 sum += abs(10*sin(double(a[i] * (b[i]+1)/ (b[i] + a[i] + 1))));
}	
printf("sum=%d\n", sum);  

```

每个线程拷贝一份sum变量，退出循环后再把各个线程的sum相加，这样就更快了

### **线程调度**

格式：#pragma omp parallel for schedule(static, size)

- **静态调度static**

编译器在执行没有使用schedule的并行指令时，默认是static子句。static在编译的过程中，就已经确定了线程的分配方案。如果不使用size制定，默认每一个线程会分配N/num_threads个迭代。也就是说，先给第一个线程直接分配N/num_threads个，依次遍历每一个线程。但是如果设置了size，首先给第一个线程分配size个迭代，然后分配到最后一个线程，再给第一个线程分配。

- **动态调度dynamic**

对于在实际运行的过程，有的线程执行速度较快，因此在执行完之后会去领取新的任务。如果不设置`size`，是会迭代每一个循环分配给各个线程，如果使用`size`，会每次分配`size`个给一个线程。

- **启发式调度guided**

采用启发式调度方法进行调度，每次分配给线程迭代次数不同，开始比较大，以后逐渐减小。size表示每次分配的迭代次数的最小值，由于每次分配的迭代次数会逐渐减少，少到size时，将不再减少。如果不知道size的大小，那么默认size为1，即一直减少到1。
每个任务分配的任务是先大后小，指数下降。当有大量任务需要循环时，刚开始为线程分配大量任务，最后任务不多时，给每个线程少量任务，可以达到线程任务均衡。

### 线程控制

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2052.png)

制导语句barrier，用它可以在并行块中设置一个路障，必须等待所有线程到达时才能通过，这个一般在并行处理循环前后存在依赖的任务时使用到。

### 其他

负载均衡：前五十次循环 small work, 后五十次循环 big work

可并行性：一个线程上的data依赖于另一个线程

**❓如果有多层循环对哪一层循环并行最好？**

(1）如果外层循环次数远远小于内层循环次数，内层循环较多时，将parallel for加在内层循环。

(2) 否则将parallel for 加在最外层循环，一般情况都是这样。

## GPU

### CUDA，如何构建并调用核函数，定义线程的功能

### overview

__global__返回值必须是void

__global__ void hello_world_kernel () {};

hello_world_kernel <<<1, 1>>>();

### 核函数声明

__device__ float DeviceFunc() 在device上执行，在device上调用

__global__ void KernelFunc() 在device上执行，在host上调用

核函数会在N个不同的CUDA线程上并行执行N次

用于执行核函数的CUDA线程数量在<<<>>>中指定    **<<<nBlk, nTid>>>(…)**   

每一个执行核函数的线程都被指定了一个特殊的线程ID

> 示例
> 

```c
__global__ void addKernel(int *c, const int *a, const int *b)
{
    int i = threadIdx.x;
    c[i] = a[i] + b[i];
}
//调用
addKernel<<<1, size>>>(dev_c, dev_a, dev_b);
```

### **线程块**

- 包含了一组线程
- 所有的线程都执行同一段代码
- 每一个线程都有对应的编号便于进行存储地址计算或者进行控制决策
- 线程之间通过共享数据以及同步执行来协作
- 来自不同线程块的线程没办法协作
- 每一个线程块中的线程数量有限制

### 线程组织结构与线程模型

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2053.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2054.png)

kernel就是运行在device上的函数

### 线程块调度

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2055.png)

每一个Block可以以任意的顺序来执行（相对于其他block)

### Built-in variables

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2056.png)

> example
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2057.png)

### 线程块例程

```c
// 1-D block for vector add
__global__ void VecAdd(float* A, float* B, float* C){// Kernel definition
   int i = threadIdx.x;
    C[i] = A[i] + B[i];
}
int main(){
    ...
    VecAdd<<<1, N>>>(A, B, C); // Kernel invocation with N threads
    ...}

// 2-D block for matrix add
__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N]){
    int i = threadIdx.x;
    int j = threadIdx.y;
    C[i][j] = A[i][j] + B[i][j];
}
int main(){
    ...
    int numBlocks = 1; // Kernel invocation with one block of N * N * 1 threads
    dim3 threadsPerBlock(N, N);
    MatAdd<<<numBlocks, threadsPerBlock>>>(A, B, C);
    ...
}

// 2-D block for matrix, add another example
__global__ void MatAdd(float A[N][N], float B[N][N], float C[N][N])
{
    int i = blockIdx.x * blockDim.x + threadIdx.x;
    int j = blockIdx.y * blockDim.y + threadIdx.y;
    if (i < N && j < N)
        C[i][j] = A[i][j] + B[i][j];
}

int main()
{
    ...
    // Kernel invocation
    dim3 threadsPerBlock(16, 16);
    dim3 numBlocks(N / threadsPerBlock.x, N / threadsPerBlock.y);
    MatAdd<<<numBlocks, threadsPerBlock>>>(A, B, C);
    ...
}
```

### GPU存储

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2058.png)

### 存储管理

> **Global memory**
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2059.png)

> **shared memory**
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2060.png)

> **local memory**
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2061.png)

> **Memcpy**
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2062.png)

### Host call device

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2063.png)

### Example

> Array Plus
> 

```c
#include "cuda_runtime.h"
#include <stdio.h>
cudaError_t addWithCuda(int *c, const int *a, const int *b, unsigned int size);
__global__ void addKernel(int *c, const int *a, const int *b){
    int i = threadIdx.x;
    c[i] = a[i] + b[i];
}

cudaError_t addWithCuda(int *c, const int *a, const int *b,  unsigned int size){
    int *dev_a = 0; int *dev_b = 0; int *dev_c = 0;
    cudaError_t cudaStatus;
    cudaStatus = cudaMalloc((void**)&dev_c, size * sizeof(int));
    if (cudaStatus != cudaSuccess) { goto Error;} 
    cudaStatus = cudaMalloc((void**)&dev_a, size * sizeof(int));
    if (cudaStatus != cudaSuccess) {goto Error;}
    cudaStatus = cudaMalloc((void**)&dev_b, size * sizeof(int));
    if (cudaStatus != cudaSuccess) {goto Error;}
    cudaStatus = cudaMemcpy(dev_a, a, size * sizeof(int),  cudaMemcpyHostToDevice); 
    if (cudaStatus != cudaSuccess) { goto Error;}
     cudaStatus = cudaMemcpy(dev_b, b, size * sizeof(int), cudaMemcpyHostToDevice);
    if (cudaStatus != cudaSuccess) {goto Error;}
    addKernel<<<1, size>>>(dev_c, dev_a, dev_b);
    cudaStatus = cudaGetLastError();
    if (cudaStatus != cudaSuccess) {goto Error;}
    cudaStatus = cudaDeviceSynchronize();
    if (cudaStatus != cudaSuccess) {goto Error;}
   cudaStatus = cudaMemcpy(c, dev_c, size * sizeof(int), cudaMemcpyDeviceToHost);
    if (cudaStatus != cudaSuccess) {goto Error;}
Error:
    cudaFree(dev_c); cudaFree(dev_a); cudaFree(dev_b);  
    return cudaStatus;}

int main(){
    const int arraySize = 5;
    const int a[arraySize] = { 1, 2, 3, 4, 5 };
    const int b[arraySize] = { 10, 20, 30, 40, 50 };
    int c[arraySize] = { 0 };
    cudaError_t cudaStatus = addWithCuda(c, a, b, arraySize); // Add vectors in parallel.
    if (cudaStatus != cudaSuccess) { return 1; }
    printf("{1,2,3,4,5} + {10,20,30,40,50} = {%d,%d,%d,%d,%d}\n", c[0], c[1], c[2], c[3], c[4]);
    cudaStatus = cudaDeviceReset();
    if (cudaStatus != cudaSuccess) {return 1; }
    return 0;
}

```

> **1D Low Pass Filter**
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2064.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2065.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2066.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2067.png)

> **Matrix Multiplication**
> 

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2068.png)

![Untitled](%E5%B5%8C%E5%85%A5%E5%BC%8F%E5%A4%8D%E4%B9%A0%E7%AC%94%E8%AE%B0%20725dae2d54374b9c8ef31fceb1f19daf/Untitled%2069.png)